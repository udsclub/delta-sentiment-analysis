{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk import word_tokenize, sent_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "replacement_patterns = [\n",
    "(r'won\\'t', 'will not'),\n",
    "(r'can\\'t', 'cannot'),\n",
    "(r'i\\'m', 'i am'),\n",
    "(r'ain\\'t', 'is not'),\n",
    "(r'(\\w+)\\'ll', '\\g<1> will'),\n",
    "(r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "(r'(\\w+)\\'ve', '\\g<1> have'),\n",
    "(r'(\\w+)\\'s', '\\g<1> is'),\n",
    "(r'(\\w+)\\'re', '\\g<1> are'),\n",
    "(r'(\\w+)\\'d', '\\g<1> would')\n",
    "]\n",
    "\n",
    "class RegexpReplacer(object):\n",
    "    def __init__(self, patterns=replacement_patterns):\n",
    "        self.patterns = [(re.compile(regex), repl) for (regex, repl) in patterns]\n",
    "    \n",
    "    def replace(self, text):\n",
    "        s = text\n",
    "        for (pattern, repl) in self.patterns:\n",
    "            s = re.sub(pattern, repl, s)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "punc_list = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preproccessing\n",
    "def tokenize_text(list_of_strings):\n",
    "    list_of_lists = list()\n",
    "    for string2 in list_of_strings:\n",
    "        string2 = RegexpReplacer().replace(string2.lower())\n",
    "        #punctuation\n",
    "        string2 = ''.join(s for s in string2 if s not in punc_list)\n",
    "        tokenized = word_tokenize(string2)\n",
    "        POS = pos_tag(tokenized)\n",
    "        word_list = [WordNetLemmatizer().lemmatize(tokenized[i], get_wordnet_pos(POS[i][1])) \n",
    "            for i in range(len(tokenized))]\n",
    "        list_of_lists.append(word_list)\n",
    "    return list_of_lists\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "        #maps pos tag so lemmatizer understands\n",
    "        from nltk.corpus import wordnet\n",
    "        if treebank_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature extraction and vectorization\n",
    "def build_feature_matrices(list_of_lists):\n",
    "    vectorizer = CountVectorizer(analyzer=lambda x: x, max_features=1000, lowercase=False)\n",
    "    X_transform = vectorizer.fit_transform(list_of_lists).toarray()\n",
    "    features_voc = vectorizer.get_feature_names()\n",
    "    return X_transform, features_voc\n",
    "\n",
    "def build_feature_matrices_test(list_of_lists):\n",
    "    # vectorize using loaded features\n",
    "    vectorizer = CountVectorizer(analyzer=lambda x: x, vocabulary = features_voc, lowercase=False)\n",
    "    X_transform = vectorizer.fit_transform(list_of_lists).toarray()\n",
    "    return X_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заменить на lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_clf(X, Y):\n",
    "    clf = RandomForestClassifier()\n",
    "    # fit Naive Bayes classifier according to X, y\n",
    "    clf.fit(X, Y)\n",
    "    print(\"Accuracy: \",clf.score(X, Y))\n",
    "    return clf\n",
    "\n",
    "def predict_clf(X, Y):\n",
    "    predictions = clf.predict(X)\n",
    "    print(\"Accuracy: \",clf.score(X, Y))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_table('reviews_clean.csv', header=0, error_bad_lines=False, delimiter='|')\n",
    "train, test = train_test_split(df, test_size = 0.5, random_state = 222)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.984727966911\n"
     ]
    }
   ],
   "source": [
    "review_word_lists = tokenize_text(train.text)\n",
    "X_transform, features_voc = build_feature_matrices(review_word_lists)\n",
    "#clf = build_clf(X_transform, train['label'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.66446214064\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "review_word_lists_test = tokenize_text(test.text)\n",
    "X_transform_test = build_feature_matrices_test(review_word_lists_test)\n",
    "#predict_clf(X_transform_test,test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
